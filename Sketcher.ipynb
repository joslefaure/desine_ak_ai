{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminjacobreji/quickdraw-cnn-demo/blob/main/Sketcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 3 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88"
      },
      "source": [
        "# !wget 'https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt'\n",
        "# !wget 'https://raw.githubusercontent.com/benjaminjacobreji/quickdraw-cnn-demo/main/fruits.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv('Angle_kreyol.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5"
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
        "for item in classes:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ"
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu"
      },
      "source": [
        "download() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/josmy/anaconda3\n",
            "\n",
            "  added / updated specs:\n",
            "    - ipywidgets\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-4.10.1               |   py38h06a4308_1         2.9 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         2.9 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                                4.9.2-py38h06a4308_0 --> 4.10.1-py38h06a4308_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? ^C\n",
            "\n",
            "CondaSystemExit: \n",
            "Operation aborted.  Exiting.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 15 10:34:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
            "| 91%   89C    P2   153W / 250W |   3025MiB / 11176MiB |     99%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
            "| 33%   43C    P5    21W / 250W |      0MiB / 11178MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A     30719      C   python                           3023MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in tqdm(enumerate(all_files)):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('/data1/quickdraw_data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-59b6cf888706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data1/quickdraw_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ab52728a65af>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(root, vfold_ratio, max_items_per_class)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#load each data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_items_per_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             raise ImportError(\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \"/user_install.html\")\n",
            "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.keras.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3JfoiYHdpk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN"
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh"
      },
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs"
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63"
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa"
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}